\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Task 2(a): Hyperparameter Optimization and Best Model}{1}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Hyperparameters evaluated in the grid search. The best configuration is marked in \textbf  {bold}.}}{2}{}\protected@file@percent }
\newlabel{tab:gridsearch_params}{{1}{2}{}{table.1}{}}
\newlabel{tab:gridsearch_params@cref}{{[table][1][]1}{[1][1][]2}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Optimal GNN Architecture}{2}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Optimal GCN Architecture and Performance on Cora}}{2}{}\protected@file@percent }
\newlabel{tab:best_model}{{2}{2}{}{table.2}{}}
\newlabel{tab:best_model@cref}{{[table][2][]2}{[1][1][]2}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Key Hyperparameter Influences}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Influence of model hyperparameters on validation accuracy. Best 10 runs are individually marked with crosses.}}{3}{}\protected@file@percent }
\newlabel{fig:gridsearch}{{1}{3}{}{figure.1}{}}
\newlabel{fig:gridsearch@cref}{{[figure][1][]1}{[1][2][]3}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Task 2(b): Homophily Analysis}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Homophily Measurement}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Overall Homophily}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Homophily Distribution}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Homophily Distribution in Cora}}{4}{}\protected@file@percent }
\newlabel{fig:homohist}{{2}{4}{}{figure.2}{}}
\newlabel{fig:homohist@cref}{{[figure][2][]2}{[1][4][]4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Predictive Performance vs. Homophily}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Experimental Design}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Findings}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Validation Accuracy Distribution Across Node Homophily Bins}}{5}{}\protected@file@percent }
\newlabel{fig:acc_vs_homophily}{{3}{5}{}{figure.3}{}}
\newlabel{fig:acc_vs_homophily@cref}{{[figure][3][]3}{[1][4][]5}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Task 2(c): Influence of Number of Convolutional Layers}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Accuracy vs. Number of Layers}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Effect of Number of Layers on Model Performance}}{6}{}\protected@file@percent }
\newlabel{fig:accuracy_vs_layers}{{4}{6}{}{figure.4}{}}
\newlabel{fig:accuracy_vs_layers@cref}{{[figure][4][]4}{[1][6][]6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Dirichlet Energy of Layer Outputs}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Dirichlet Energy per Layer for Different Number of Layers}}{7}{}\protected@file@percent }
\newlabel{fig:dirichlet_energy_layers}{{5}{7}{}{figure.5}{}}
\newlabel{fig:dirichlet_energy_layers@cref}{{[figure][5][]5}{[1][6][]7}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Task 2(d): Effect of label change on oversmoothing}{7}{}\protected@file@percent }
\citation{rusch2023surveyoversmoothinggraphneural}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Dirichlet Energy per Layer for Different Number of Layers when predicting Node Degree}}{8}{}\protected@file@percent }
\newlabel{fig:dirichlet_energy_layers_node_degree_prediction}{{6}{8}{}{figure.6}{}}
\newlabel{fig:dirichlet_energy_layers_node_degree_prediction@cref}{{[figure][6][]6}{[1][7][]8}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Task 2(e): Oversmoothing and Activation Functions}{8}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Effect of Activation Function on Model Performance}}{9}{}\protected@file@percent }
\newlabel{fig:activation_function_comparison_accuracy}{{7}{9}{}{figure.7}{}}
\newlabel{fig:activation_function_comparison_accuracy@cref}{{[figure][7][]7}{[1][8][]9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Dirichlet Energy per Layer for Different Number of Layers - ReLU Activation}}{10}{}\protected@file@percent }
\newlabel{fig:dirichlet_energy_layers_activation_ReLU}{{8}{10}{}{figure.8}{}}
\newlabel{fig:dirichlet_energy_layers_activation_ReLU@cref}{{[figure][8][]8}{[1][9][]10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Dirichlet Energy per Layer for Different Number of Layers - Linear Activation}}{10}{}\protected@file@percent }
\newlabel{fig:dirichlet_energy_layers_activation_Linear}{{9}{10}{}{figure.9}{}}
\newlabel{fig:dirichlet_energy_layers_activation_Linear@cref}{{[figure][9][]9}{[1][10][]10}{}{}{}}
\bibstyle{plain}
\bibdata{references}
\bibcite{rusch2023surveyoversmoothinggraphneural}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Dirichlet Energy per Layer for Different Number of Layers - Sigmoid Activation}}{11}{}\protected@file@percent }
\newlabel{fig:dirichlet_energy_layers_activation_Sigmoid}{{10}{11}{}{figure.10}{}}
\newlabel{fig:dirichlet_energy_layers_activation_Sigmoid@cref}{{[figure][10][]10}{[1][10][]11}{}{}{}}
\gdef \@abspage@last{11}
